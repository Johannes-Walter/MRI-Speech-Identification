{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23FvrnhOSyU6"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iz5VSDRINtU",
        "outputId": "fa049132-8b10-49da-9478-005263a16196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2G3TsA8JsSW",
        "outputId": "b3a21d81-9bcc-45c5-90eb-4496f54695e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " data   data_preparer.py  'H&M.ipynb'   __pycache__   train.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEdkco1xIBTR"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/drive/My Drive/Colab Notebooks\")\n",
        "import data_preparer\n",
        "from pathlib import Path\n",
        "from keras.utils import to_categorical\n",
        "import torch\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmFUWY3OKYGR",
        "outputId": "6e25263a-787e-4257-9d06-051374b85745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spacing: 30.0 degrees\n"
          ]
        }
      ],
      "source": [
        "#prepare mask for vectors\n",
        "rel = data_preparer.get_vectors_relative_position(7, 180, 20)\n",
        "abss = data_preparer.get_vectors_absolute_position(rel)\n",
        "mask = data_preparer.get_mask(abss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26YYbrAsKbMO"
      },
      "outputs": [],
      "source": [
        "#read recon file\n",
        "file = \"sub001_2drt_07_grandfather1_r1_recon.h5\"\n",
        "filepath = f\"/content/drive/My Drive/Colab Notebooks/data/sub001/2drt/recon/{file}\"\n",
        "recon = data_preparer.get_recon(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QrhXdCSKwb5"
      },
      "outputs": [],
      "source": [
        "#read timestamps file\n",
        "filepath = \"/content/drive/My Drive/Colab Notebooks/data/sub001/timestamps/sub001_2drt_01_vcv1_r1_recon.csv\"\n",
        "timestamps = data_preparer.read_timestamps(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugRwlIeUKzD8"
      },
      "outputs": [],
      "source": [
        "#get vectors of the first row of timestamps\n",
        "vectors = data_preparer.get_pixel_data(recon, abss, timestamps.iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Meid7Gv0Eb_1"
      },
      "outputs": [],
      "source": [
        "vector1 = data_preparer.get_pixel_data(recon, abss, timestamps.iloc[0])\n",
        "vector2 = data_preparer.get_pixel_data(recon, abss, timestamps.iloc[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyxWO4S961xH",
        "outputId": "884b1e56-7f4f-44ae-c7c8-345fe27fdd32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 20, 52)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJG1jCbugDZW"
      },
      "outputs": [],
      "source": [
        "timestamps['total frames'] = timestamps['last_frame'] - timestamps['first_frame'] #create new col to get the higehst number of frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szlEz1avhBfN",
        "outputId": "6284fcca-d3bb-409f-c84f-ba8e729e7974"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "highest_framenr = round(timestamps['total frames'].max())\n",
        "highest_framenr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUFrxAPSLhj2"
      },
      "outputs": [],
      "source": [
        "#convert np array to tensors from pytroch\n",
        "tensor1 = torch.from_numpy(vector1.copy())\n",
        "tensor2 = torch.from_numpy(vector2.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4lrG2DsIZpR"
      },
      "outputs": [],
      "source": [
        "# expand tensor2 along the third dimension to match the size of tensor1\n",
        "tensor2 = torch.cat((tensor2, torch.zeros(7, 20, 12)), dim=2)\n",
        "# stack the tensors along a new first dimension\n",
        "stacked_tensor = torch.stack([tensor1, tensor2], dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFI1NYkqO-ER",
        "outputId": "5caa1a33-120e-4934-80cf-547eace0c1ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 7, 20, 52])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stacked_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opJn-ggXiOlH",
        "outputId": "23ae6589-4f95-4c7c-ff5d-22d39d6d6bce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "highest_framenr - round(timestamps.iloc[0]['total frames'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVUoujNM-WfK"
      },
      "outputs": [],
      "source": [
        "files = ['sub001-2drt_01_vcv1_r1_recon', 'sub001_2drt_02_vcv2_r1_recon']\n",
        "X,y = get_data(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxsArHD76lnk"
      },
      "outputs": [],
      "source": [
        "#TO DO: write function which can read multiple files an output it to X (pixel vektor arry) and y (lettercat)\n",
        "def get_data(filename_list):\n",
        "  #prepare mask for vectors\n",
        "  rel = data_preparer.get_vectors_relative_position(7, 180, 20)\n",
        "  abss = data_preparer.get_vectors_absolute_position(rel)\n",
        "  mask = data_preparer.get_mask(abss)\n",
        "\n",
        "  #read timestamp files and append them to one large dataframe\n",
        "  all_timestamps = pd.DataFrame({})\n",
        "  for file in filename_list:\n",
        "    filepath = f\"/content/drive/My Drive/Colab Notebooks/data/sub001/timestamps/{file}.csv\"\n",
        "    timestamps = data_preparer.read_timestamps(filepath)\n",
        "    timestamps['recon'] = file\n",
        "    all_timestamps = all_timestamps.append(timestamps, reset_index=True)\n",
        "\n",
        "#now get pixel vector data with iterating over the large dataframe\n",
        "  tensor_list = []\n",
        "  all_timestamps['total frames'] = all_timestamps['last_frame'] - all_timestamps['first_frame'] #create new col to get the higehst number of frames\n",
        "  highest_framenr = round(all_timestamps['total frames'].max())\n",
        "  for i in range(len(all_timestamps)):\n",
        "    filepath = f\"/content/drive/My Drive/Colab Notebooks/data/sub001/2drt/recon/{all_timestamps['recon']}\"\n",
        "    recon = data_preparer.get_recon(filepath)\n",
        "    vectors = data_preparer.get_pixel_data(recon, abss, all_timestamps.iloc[i])\n",
        "    tensor = torch.from_numpy(vectors.copy())\n",
        "    if round(all_timestamps.iloc[i]['total frames']) != highest_framenr:\n",
        "      delta_frames = highest_framenr - round(all_timestamps.iloc[i]['total frames'])\n",
        "      tensor = torch.cat((tensor, torch.zeros(7, 20, delta_frames)), dim=2)\n",
        "    tensor_list.append(tensor)\n",
        "  final_tensor = torch.stack(tensor_list, dim=0)\n",
        "  #convert the letters to numeric categories\n",
        "  all_timestamps['Buchstabe'] = all_timestamps['Buchstabe'].astype('category') #convert to catergory type\n",
        "  all_timestamps['letter_cat'] = all_timestamps[\"Buchstabe\"].cat.codes # get new col with numeric category\n",
        "  #define X an y\n",
        "  X = final_tensor\n",
        "  y = all_timestamps['letter_cat']\n",
        "  return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN1g5sNWPmVs"
      },
      "outputs": [],
      "source": [
        "#need to stack all arrays from timestamps together\n",
        "#therfore torch.cat needs to be applied to all arrays that are not the largest size in dimension 2\n",
        "#so we first need to find out how long the dimension 2 can be at max\n",
        "#and then apply torch.cat((smallervector, torch.zeros(7,20,numbertomxlen)), dim=2)\n",
        "#after that all tensors can be stacked\n",
        "highest_framenr = round(timestamps['total frames'].max())\n",
        "tensor_list = []\n",
        "for i in range(len(timestamps)):\n",
        "  vectors = data_preparer.get_pixel_data(recon, abss, timestamps.iloc[i])\n",
        "  tensor = torch.from_numpy(vectors.copy())\n",
        "  if round(timestamps.iloc[i]['total frames']) != highest_framenr:\n",
        "    delta_frames = highest_framenr - round(timestamps.iloc[i]['total frames'])\n",
        "    tensor = torch.cat((tensor, torch.zeros(7, 20, delta_frames)), dim=2)\n",
        "  tensor_list.append(tensor)\n",
        "final_tensor = torch.stack(tensor_list, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koUwbSDakcI1",
        "outputId": "a03670c3-b8b1-483a-cf5f-07c38be94f83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([36, 7, 20, 80])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0gxrFWYmKGC"
      },
      "outputs": [],
      "source": [
        "#convert it back to numpy and then to tensorflow to use it for training\n",
        "np_tensor = final_tensor.numpy()\n",
        "tf_tensor = tf.convert_to_tensor(np_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e38HGi3xK4A9"
      },
      "outputs": [],
      "source": [
        "#and the label/letter of the vectors\n",
        "timestamps['Buchstabe'] = timestamps['Buchstabe'].astype('category') #convert to catergory type\n",
        "timestamps['letter_cat'] = timestamps[\"Buchstabe\"].cat.codes # get new col with numeric category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0P6YktHOkff"
      },
      "outputs": [],
      "source": [
        "#X = np_tensor.reshape((36, 7, -1))\n",
        "X = np_tensor#vectors\n",
        "X = np.reshape(X, (36, 80, 140))\n",
        "y = timestamps['letter_cat']#letter\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGvazg4_454L",
        "outputId": "5094eb0a-94f0-4bc0-8b98-5e3f0fdd1ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 80, 140)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1sAaZoIYYn0"
      },
      "source": [
        "Start the training..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhk7T02DVO0a"
      },
      "source": [
        "Used: https://medium.com/@dclengacher/keras-lstm-recurrent-neural-networks-c1f5febde03d & https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/sentiment_analysis/Keras%20LSTM%20for%20IMDB%20Sentiment%20Classification.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnF6kjSuU2e-"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, TimeDistributed\n",
        "from keras.layers import LSTM, Bidirectional, Conv1D, concatenate, Permute, Dropout\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YS2EoEsEeKQ"
      },
      "source": [
        "**1. LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9iqununyXHN"
      },
      "outputs": [],
      "source": [
        "X = np.reshape(np_tensor, (36, 80, 140)) #due that LSTM model taskes only 3 dimension as input we reshape our data to (batchsize,timephrames, vektors*pixels)\n",
        "y = timestamps['letter_cat']#letter\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfoh7psRU5Pp",
        "outputId": "47159fe6-6889-4656-fa64-74582f9eb887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9049 - accuracy: 0.2500 - val_loss: 0.9161 - val_accuracy: 0.3750\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.8387 - accuracy: 0.3571 - val_loss: 0.8685 - val_accuracy: 0.3750\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.7462 - accuracy: 0.4286 - val_loss: 0.8466 - val_accuracy: 0.2500\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.7074 - accuracy: 0.4286 - val_loss: 0.8213 - val_accuracy: 0.2500\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6400 - accuracy: 0.3929 - val_loss: 0.7722 - val_accuracy: 0.2500\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5673 - accuracy: 0.3929 - val_loss: 0.7201 - val_accuracy: 0.3750\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4541 - accuracy: 0.3929 - val_loss: 0.6988 - val_accuracy: 0.3750\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4035 - accuracy: 0.3929 - val_loss: 0.6626 - val_accuracy: 0.3750\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3750 - accuracy: 0.3929 - val_loss: 0.6467 - val_accuracy: 0.3750\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.3366 - accuracy: 0.3929 - val_loss: 0.6468 - val_accuracy: 0.3750\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6468 - accuracy: 0.3750\n"
          ]
        }
      ],
      "source": [
        "#set up the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(10,return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=36,\n",
        "          epochs=10,\n",
        "          validation_data=(X_test, y_test))\n",
        "score, acc = model.evaluate(X_test, y_test,\n",
        "                            batch_size=36)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGyVomJiEqsr"
      },
      "source": [
        "**2. 3D-CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmFip3f9yzDu"
      },
      "outputs": [],
      "source": [
        "X = np_tensor#vectors\n",
        "y = timestamps['letter_cat']#letter\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS-g2YGsEp4z",
        "outputId": "fcc734c9-ddf7-489a-a5c8-67a9ef021c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 2s 171ms/step - loss: 120.6244 - accuracy: 0.3182 - val_loss: 476.0052 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 1s 149ms/step - loss: -98.0341 - accuracy: 0.3182 - val_loss: 313.7749 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 1s 151ms/step - loss: -104.7441 - accuracy: 0.3182 - val_loss: 338.0464 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 1s 146ms/step - loss: -220.2292 - accuracy: 0.3182 - val_loss: 638.2670 - val_accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 1s 154ms/step - loss: -214.2230 - accuracy: 0.3182 - val_loss: 2279.3870 - val_accuracy: 0.3333\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 1s 142ms/step - loss: -1110.5559 - accuracy: 0.3182 - val_loss: 3405.1633 - val_accuracy: 0.3333\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 1s 151ms/step - loss: -1141.2543 - accuracy: 0.3182 - val_loss: 9065.5244 - val_accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 1s 148ms/step - loss: -2870.7937 - accuracy: 0.3182 - val_loss: 7760.8726 - val_accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 1s 151ms/step - loss: -4478.3052 - accuracy: 0.3182 - val_loss: 9591.4795 - val_accuracy: 0.3333\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 1s 245ms/step - loss: -5491.0063 - accuracy: 0.3182 - val_loss: 17423.3496 - val_accuracy: 0.3333\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 7586.8994 - accuracy: 0.3750\n",
            "Test loss: 7586.8994140625\n",
            "Test accuracy: 0.375\n"
          ]
        }
      ],
      "source": [
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(7, 20, 80, 1)))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=4, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "score = model.evaluate(X_test, y_test, batch_size=4)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
